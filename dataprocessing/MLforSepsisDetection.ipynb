{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510eae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepsis_label\n",
      "False    174236\n",
      "True       6415\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# STEP 1: Load diagnoses_icd\n",
    "diag = pd.read_csv(\"path_to_mimic/mimic-iv-2.1/hosp/diagnoses_icd.csv\", usecols=[\"subject_id\", \"icd_code\"])\n",
    "\n",
    "# STEP 2: Function to identify sepsis ICD codes\n",
    "def is_sepsis(code):\n",
    "    code = str(code)\n",
    "    return code.startswith(\"A41\") or code.startswith(\"R65\")\n",
    "\n",
    "diag[\"sepsis_label\"] = diag[\"icd_code\"].apply(is_sepsis)\n",
    "\n",
    "# STEP 3: Aggregate to one row per subject\n",
    "sepsis_labels = diag.groupby(\"subject_id\")[\"sepsis_label\"].max().reset_index()\n",
    "print(sepsis_labels[\"sepsis_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_labels.to_csv(\"H:/path_to_mimic/sepsis_labels.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Matching for: heart rate ---\n",
      "   itemid                    label     abbreviation      linksto  \\\n",
      "2  220045               Heart Rate               HR  chartevents   \n",
      "3  220046  Heart rate Alarm - High  HR Alarm - High  chartevents   \n",
      "4  220047   Heart Rate Alarm - Low   HR Alarm - Low  chartevents   \n",
      "\n",
      "              category unitname param_type  lownormalvalue  highnormalvalue  \n",
      "2  Routine Vital Signs      bpm    Numeric             NaN              NaN  \n",
      "3               Alarms      bpm    Numeric             NaN              NaN  \n",
      "4               Alarms      bpm    Numeric             NaN              NaN  \n",
      "\n",
      "--- Matching for: blood pressure ---\n",
      "      itemid                                     label         abbreviation  \\\n",
      "6     220050          Arterial Blood Pressure systolic                 ABPs   \n",
      "7     220051         Arterial Blood Pressure diastolic                 ABPd   \n",
      "8     220052              Arterial Blood Pressure mean                 ABPm   \n",
      "9     220056       Arterial Blood Pressure Alarm - Low      ABP Alarm - Low   \n",
      "10    220058      Arterial Blood Pressure Alarm - High     ABP Alarm - High   \n",
      "24    220179      Non Invasive Blood Pressure systolic                 NBPs   \n",
      "25    220180     Non Invasive Blood Pressure diastolic                 NBPd   \n",
      "26    220181          Non Invasive Blood Pressure mean                 NBPm   \n",
      "330   223751  Non-Invasive Blood Pressure Alarm - High     NBP Alarm - High   \n",
      "331   223752   Non-Invasive Blood Pressure Alarm - Low      NBP Alarm - Low   \n",
      "575   224167       Manual Blood Pressure Systolic Left         Manual BPs L   \n",
      "768   224643      Manual Blood Pressure Diastolic Left         Manual BPd L   \n",
      "2154  227242     Manual Blood Pressure Diastolic Right         Manual BPd R   \n",
      "2155  227243      Manual Blood Pressure Systolic Right         Manual BPs R   \n",
      "2267  227537           ART Blood Pressure Alarm - High  ART BP Alarm - High   \n",
      "2268  227538            ART Blood Pressure Alarm - Low   ART BP Alarm - Low   \n",
      "2269  227539           ART Blood Pressure Alarm Source  ART BP Alarm Source   \n",
      "\n",
      "          linksto             category unitname param_type  lownormalvalue  \\\n",
      "6     chartevents  Routine Vital Signs     mmHg    Numeric            90.0   \n",
      "7     chartevents  Routine Vital Signs     mmHg    Numeric            60.0   \n",
      "8     chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "9     chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "10    chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "24    chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "25    chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "26    chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "330   chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "331   chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "575   chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "768   chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2154  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2155  chartevents  Routine Vital Signs     mmHg    Numeric             NaN   \n",
      "2267  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2268  chartevents               Alarms     mmHg    Numeric             NaN   \n",
      "2269  chartevents               Alarms      NaN       Text             NaN   \n",
      "\n",
      "      highnormalvalue  \n",
      "6               140.0  \n",
      "7                90.0  \n",
      "8                 NaN  \n",
      "9                 NaN  \n",
      "10                NaN  \n",
      "24                NaN  \n",
      "25                NaN  \n",
      "26                NaN  \n",
      "330               NaN  \n",
      "331               NaN  \n",
      "575               NaN  \n",
      "768               NaN  \n",
      "2154              NaN  \n",
      "2155              NaN  \n",
      "2267              NaN  \n",
      "2268              NaN  \n",
      "2269              NaN  \n",
      "\n",
      "--- Matching for: spo2 ---\n",
      "      itemid                          label                   abbreviation  \\\n",
      "1810  226253               SpO2 Desat Limit               SpO2 Desat Limit   \n",
      "3920  229862  Forehead SpO2 Sensor in Place  Forehead SpO2 Sensor in Place   \n",
      "\n",
      "          linksto             category unitname param_type  lownormalvalue  \\\n",
      "1810  chartevents               Alarms        %    Numeric             NaN   \n",
      "3920  chartevents  Routine Vital Signs      NaN   Checkbox             NaN   \n",
      "\n",
      "      highnormalvalue  \n",
      "1810              NaN  \n",
      "3920              NaN  \n",
      "\n",
      "--- Matching for: temperature ---\n",
      "      itemid                        label                 abbreviation  \\\n",
      "337   223761       Temperature Fahrenheit                Temperature F   \n",
      "338   223762          Temperature Celsius                Temperature C   \n",
      "505   224027             Skin Temperature                    Skin Temp   \n",
      "767   224642             Temperature Site                    Temp Site   \n",
      "790   224674       Changes in Temperature       Changes in Temperature   \n",
      "1814  226329    Blood Temperature CCO (C)           Blood Temp CCO (C)   \n",
      "2097  227054        TemperatureF_ApacheIV        TemperatureF_ApacheIV   \n",
      "2776  228242  Pt. Temperature (BG) (SOFT)  Pt. Temperature (BG) (SOFT)   \n",
      "3466  229236     Cerebral Temperature (C)               Cerebral T (C)   \n",
      "\n",
      "          linksto                category unitname param_type  lownormalvalue  \\\n",
      "337   chartevents     Routine Vital Signs       °F    Numeric             NaN   \n",
      "338   chartevents     Routine Vital Signs       °C    Numeric             NaN   \n",
      "505   chartevents       Skin - Assessment      NaN       Text             NaN   \n",
      "767   chartevents     Routine Vital Signs      NaN       Text             NaN   \n",
      "790   chartevents              Toxicology      NaN       Text             NaN   \n",
      "1814  chartevents     Routine Vital Signs       °C    Numeric             NaN   \n",
      "2097  chartevents  Scores - APACHE IV (2)       °F    Numeric             NaN   \n",
      "2776  chartevents                    Labs      NaN    Numeric             NaN   \n",
      "3466  chartevents            Hemodynamics       °C    Numeric             NaN   \n",
      "\n",
      "      highnormalvalue  \n",
      "337               NaN  \n",
      "338               NaN  \n",
      "505               NaN  \n",
      "767               NaN  \n",
      "790               NaN  \n",
      "1814              NaN  \n",
      "2097              NaN  \n",
      "2776              NaN  \n",
      "3466              NaN  \n",
      "\n",
      "--- Matching for: respiratory rate ---\n",
      "     itemid                           label                    abbreviation  \\\n",
      "28   220210                Respiratory Rate                              RR   \n",
      "799  224688          Respiratory Rate (Set)          Respiratory Rate (Set)   \n",
      "800  224689  Respiratory Rate (spontaneous)  Respiratory Rate (spontaneous)   \n",
      "801  224690        Respiratory Rate (Total)        Respiratory Rate (Total)   \n",
      "\n",
      "         linksto     category  unitname param_type  lownormalvalue  \\\n",
      "28   chartevents  Respiratory  insp/min    Numeric             NaN   \n",
      "799  chartevents  Respiratory  insp/min    Numeric             NaN   \n",
      "800  chartevents  Respiratory  insp/min    Numeric             NaN   \n",
      "801  chartevents  Respiratory  insp/min    Numeric             NaN   \n",
      "\n",
      "     highnormalvalue  \n",
      "28               NaN  \n",
      "799              NaN  \n",
      "800              NaN  \n",
      "801             36.0  \n"
     ]
    }
   ],
   "source": [
    "d_items = pd.read_csv(\"H:/path_to_mimic/archive/mimic-iv-2.1/icu/d_items.csv\")\n",
    "\n",
    "keywords = [\"heart rate\", \"blood pressure\", \"spo2\", \"temperature\", \"respiratory rate\"]\n",
    "for key in keywords:\n",
    "    print(f\"\\n--- Matching for: {key} ---\")\n",
    "    print(d_items[d_items[\"label\"].str.lower().str.contains(key)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define all selected itemids\n",
    "vital_itemids = [\n",
    "    220045,  # Heart Rate\n",
    "    220050, 220179,  # Systolic\n",
    "    220051, 220180,  # Diastolic\n",
    "    220052, 220181,  # Mean BP\n",
    "    226253,          # SpO2\n",
    "    223761, 223762,  # Temp\n",
    "    220210, 224690   # Resp Rate\n",
    "]\n",
    "\n",
    "# Define path\n",
    "chartevents_path = \"H:/path_to_mimic/archive/mimic-iv-2.1/icu/chartevents.csv\"\n",
    "\n",
    "# Create storage\n",
    "feature_rows = []\n",
    "\n",
    "# Chunked reading\n",
    "chunks = pd.read_csv(chartevents_path, usecols=[\"subject_id\", \"itemid\", \"valuenum\"], chunksize=1000000)\n",
    "\n",
    "for chunk in chunks:\n",
    "    chunk = chunk[chunk[\"itemid\"].isin(vital_itemids)]\n",
    "    # Simple aggregation\n",
    "    stats = chunk.groupby([\"subject_id\", \"itemid\"])[\"valuenum\"].agg([\"mean\", \"min\", \"max\"]).reset_index()\n",
    "    feature_rows.append(stats)\n",
    "\n",
    "# Combine all chunks\n",
    "vital_stats = pd.concat(feature_rows)\n",
    "\n",
    "# … everything up to vital_stats = pd.concat(feature_rows) stays the same …\n",
    "\n",
    "# Now build the wide table with automatic aggregation:\n",
    "features = (\n",
    "    vital_stats\n",
    "    .pivot_table(\n",
    "        index=\"subject_id\",\n",
    "        columns=\"itemid\",\n",
    "        values=[\"mean\", \"min\", \"max\"],\n",
    "        aggfunc=\"mean\"      # when duplicates exist, take the mean of means/mins/maxs\n",
    "    )\n",
    ")\n",
    "\n",
    "# Flatten the MultiIndex columns:\n",
    "features.columns = [f\"{stat}_{itemid}\" for stat, itemid in features.columns]\n",
    "features = features.reset_index()\n",
    "\n",
    "# (Optional) save to CSV\n",
    "features.to_csv(\"H:/path_to_mimic/vitals_features.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0d135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 180651 total, 180641 train, 10 test\n",
      "After merge+impute → train shape (180641, 38), test shape (10, 38)\n",
      "\n",
      "Test classification report on your 10 patients:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.40      0.57        10\n",
      "        True       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.50      0.20      0.29        10\n",
      "weighted avg       1.00      0.40      0.57        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ─── 1) Load features & labels ──────────────────────────────────────────────────\n",
    "features = pd.read_csv(\"H:/path_to_mimic/vitals_features.csv\")    # subject_id + feature cols\n",
    "labels   = pd.read_csv(\"H:/path_to_mimic/sepsis_labels.csv\")      # subject_id + sepsis_label\n",
    "\n",
    "# List your fixed 10 test patients\n",
    "TEST_IDS = [\n",
    "    10009628, 10024982, 10007058, 10011668, 10014729,\n",
    "    10019350, 10002443, 10017285, 10018328, 10008077\n",
    "]\n",
    "\n",
    "# ─── 2) Split labels into train/test label sets ────────────────────────────────\n",
    "labels_train = labels[~labels[\"subject_id\"].isin(TEST_IDS)]\n",
    "labels_test  = labels[ labels[\"subject_id\"].isin(TEST_IDS)]\n",
    "\n",
    "print(f\"Labels: {labels.shape[0]} total, {labels_train.shape[0]} train, {labels_test.shape[0]} test\")\n",
    "\n",
    "# ─── 3) Merge features INTO each set ────────────────────────────────────────────\n",
    "#   - use left join so every label keeps its row, even if features are missing\n",
    "train = labels_train.merge(features, on=\"subject_id\", how=\"left\")\n",
    "test  = labels_test .merge(features, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# Identify feature columns\n",
    "feat_cols = [c for c in train.columns if c not in (\"subject_id\",\"sepsis_label\")]\n",
    "\n",
    "# ─── 4) Impute missing feature values ───────────────────────────────────────────\n",
    "# Compute medians on training data\n",
    "medians = train[feat_cols].median()\n",
    "\n",
    "# Fill NaNs in both train & test using training medians\n",
    "train[feat_cols] = train[feat_cols].fillna(medians)\n",
    "test[feat_cols]  = test[feat_cols].fillna(medians)\n",
    "\n",
    "# (Optional) if any remain, fill with zero\n",
    "train[feat_cols] = train[feat_cols].fillna(0)\n",
    "test[feat_cols]  = test[feat_cols].fillna(0)\n",
    "\n",
    "print(f\"After merge+impute → train shape {train.shape}, test shape {test.shape}\")\n",
    "\n",
    "# ─── 5) Train & Evaluate ───────────────────────────────────────────────────────\n",
    "X_train, y_train = train[feat_cols], train[\"sepsis_label\"]\n",
    "X_test,  y_test  = test [feat_cols],  test [\"sepsis_label\"]\n",
    "\n",
    "clf = LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nTest classification report on your 10 patients:\")\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9225f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to sepsis_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# assume `log_pipeline` is the Pipeline you fitted:\n",
    "# Pipeline([(\"scaler\", StandardScaler()), (\"clf\", LogisticRegression(...))])\n",
    "joblib.dump(log_pipeline, \"sepsis_model.pkl\")\n",
    "print(\"Model saved to sepsis_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject_id  risk_score\n",
      "11     10002443    0.511466\n",
      "43     10007058    0.276585\n",
      "49     10008077    0.518878\n",
      "56     10009628    0.393179\n",
      "66     10011668    0.438867\n",
      "86     10014729    0.374077\n",
      "94     10017285    0.776982\n",
      "102    10018328    0.071844\n",
      "110    10019350    0.221950\n",
      "148    10024982    0.967730\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# ─── 1) Load your precomputed features and pipeline ─────────────────────────────\n",
    "features = pd.read_csv(\"H:/path_to_mimic/vitals_features.csv\")\n",
    "pipeline = joblib.load(\"sepsis_model.pkl\")   # your saved sklearn Pipeline\n",
    "\n",
    "# ─── 2) Define your test patient IDs ────────────────────────────────────────────\n",
    "test_ids = [\n",
    "    10009628, 10024982, 10007058, 10011668, 10014729,\n",
    "    10019350, 10002443, 10017285, 10018328, 10008077\n",
    "]\n",
    "\n",
    "# ─── 3) Filter to just those patients ────────────────────────────────────────────\n",
    "test_df = features[features[\"subject_id\"].isin(test_ids)].copy()\n",
    "\n",
    "# ─── 4) Prepare feature matrix ──────────────────────────────────────────────────\n",
    "feat_cols = [c for c in test_df.columns if c != \"subject_id\"]\n",
    "X_test = test_df[feat_cols]\n",
    "\n",
    "# If you used median imputation during training, repeat it here:\n",
    "# medians = pd.Series(...)  # compute or hard‐code your training medians\n",
    "# X_test = X_test.fillna(medians).fillna(0)\n",
    "\n",
    "# Or simply:\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# ─── 5) Compute risk probabilities ───────────────────────────────────────────────\n",
    "test_df[\"risk_score\"] = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "# ─── 6) Display the results ──────────────────────────────────────────────────────\n",
    "print(test_df[[\"subject_id\", \"risk_score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8907c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scaler': StandardScaler(), 'clf': LogisticRegression(class_weight='balanced', max_iter=2000, random_state=42,\n",
      "                   solver='saga')}\n",
      "['max_220045' 'max_220050' 'max_220051' 'max_220052' 'max_220179'\n",
      " 'max_220180' 'max_220181' 'max_220210' 'max_223761' 'max_223762'\n",
      " 'max_224690' 'max_226253' 'mean_220045' 'mean_220050' 'mean_220051'\n",
      " 'mean_220052' 'mean_220179' 'mean_220180' 'mean_220181' 'mean_220210'\n",
      " 'mean_223761' 'mean_223762' 'mean_224690' 'mean_226253' 'min_220045'\n",
      " 'min_220050' 'min_220051' 'min_220052' 'min_220179' 'min_220180'\n",
      " 'min_220181' 'min_220210' 'min_223761' 'min_223762' 'min_224690'\n",
      " 'min_226253']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load model\n",
    "model = joblib.load('sepsis_model.pkl')\n",
    "\n",
    "# If it was trained using a pipeline with a feature selector or transformer\n",
    "if hasattr(model, 'named_steps'):\n",
    "    print(model.named_steps)\n",
    "\n",
    "# Most reliable: check the feature names from training\n",
    "# This only works if you saved feature names during training\n",
    "print(model.feature_names_in_)  # Available in scikit-learn 1.0+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0611b25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lr_weights.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, numpy as np, pandas as pd\n",
    "\n",
    "# 1) Load your pipeline\n",
    "pipeline = joblib.load(\"sepsis_model.pkl\")\n",
    "scaler   = pipeline.named_steps[\"scaler\"]\n",
    "clf      = pipeline.named_steps[\"clf\"]\n",
    "\n",
    "# 2) Compute raw weights\n",
    "feat_names      = scaler.feature_names_in_\n",
    "means, scales   = scaler.mean_, scaler.scale_\n",
    "coefs_scaled    = clf.coef_[0]\n",
    "intercept_scaled= clf.intercept_[0]\n",
    "\n",
    "coefs_raw     = coefs_scaled / scales\n",
    "intercept_raw = intercept_scaled - np.sum(coefs_scaled * (means / scales))\n",
    "\n",
    "# 3) Build a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"feature\" : [\"intercept\"] + list(feat_names),\n",
    "    \"weight\"  : [intercept_raw] + list(coefs_raw)\n",
    "})\n",
    "\n",
    "# 4) Save to CSV\n",
    "df.to_csv(\"lr_weights.csv\", index=False)\n",
    "print(\"Saved lr_weights.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3dfb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48caedc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89340c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610e5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86663780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9459cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a371c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed4a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad82eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepsis_label\n",
      "False    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test[\"sepsis_label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b900e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test label balance:\n",
      " sepsis_label\n",
      "True     4\n",
      "False    1\n",
      "Name: count, dtype: int64\n",
      "Train size: 50929 Test size: 5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58355d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 180641   Test size: 10\n",
      "Test label distribution:\n",
      " sepsis_label\n",
      "True     5\n",
      "False    5\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (scaled) results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.71      1.00      0.83         5\n",
      "        True       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.86      0.80      0.79        10\n",
      "weighted avg       0.86      0.80      0.79        10\n",
      "\n",
      "Random Forest results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      1.00      0.67         5\n",
      "        True       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.25      0.50      0.33        10\n",
      "weighted avg       0.25      0.50      0.33        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "h:\\EE547\\archive\\mimic-iv-2.1\\dataenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ─── 1) Load features & labels ─────────────────────────────────────────────────\n",
    "features = pd.read_csv(\"H:/path_to_mimic/vitals_features.csv\")\n",
    "labels   = pd.read_csv(\"H:/path_to_mimic/sepsis_labels.csv\")\n",
    "\n",
    "# ─── 2) Build stratified 10-patient test set (5 septic + 5 non-septic) ──────────\n",
    "septic_ids    = labels[ labels.sepsis_label ==  True][\"subject_id\"].unique()\n",
    "nonseptic_ids = labels[ labels.sepsis_label == False][\"subject_id\"].unique()\n",
    "rng = np.random.default_rng(42)\n",
    "test_septic    = rng.choice(septic_ids,    size=5, replace=False)\n",
    "test_nonseptic = rng.choice(nonseptic_ids, size=5, replace=False)\n",
    "TEST_IDS = np.concatenate([test_septic, test_nonseptic])\n",
    "\n",
    "# ─── 3) Split labels & merge features ───────────────────────────────────────────\n",
    "labels_train = labels[~labels.subject_id.isin(TEST_IDS)]\n",
    "labels_test  = labels[ labels.subject_id.isin(TEST_IDS)]\n",
    "\n",
    "train_df = labels_train.merge(features, on=\"subject_id\", how=\"left\")\n",
    "test_df  = labels_test .merge(features, on=\"subject_id\", how=\"left\")\n",
    "\n",
    "# ─── 4) Identify feature columns ────────────────────────────────────────────────\n",
    "feat_cols = [c for c in train_df.columns if c not in (\"subject_id\",\"sepsis_label\")]\n",
    "\n",
    "# ─── 5) Drop columns with no data in training set ──────────────────────────────\n",
    "medians    = train_df[feat_cols].median()\n",
    "empty_cols = medians[medians.isna()].index.tolist()\n",
    "if empty_cols:\n",
    "    print(\"Dropping empty cols:\", empty_cols)\n",
    "    train_df.drop(columns=empty_cols, inplace=True)\n",
    "    test_df.drop(columns=empty_cols,  inplace=True)\n",
    "    feat_cols = [c for c in feat_cols if c not in empty_cols]\n",
    "    medians   = medians.drop(index=empty_cols)\n",
    "\n",
    "# ─── 6) Impute remaining missing with train-set medians ─────────────────────────\n",
    "train_df[feat_cols] = train_df[feat_cols].fillna(medians)\n",
    "test_df [feat_cols] = test_df [feat_cols].fillna(medians)\n",
    "\n",
    "# (Optional) fill any stragglers with zero\n",
    "train_df[feat_cols] = train_df[feat_cols].fillna(0)\n",
    "test_df [feat_cols] = test_df [feat_cols].fillna(0)\n",
    "\n",
    "# ─── 7) Prepare X/y ─────────────────────────────────────────────────────────────\n",
    "X_train, y_train = train_df[feat_cols], train_df[\"sepsis_label\"]\n",
    "X_test,  y_test  = test_df [feat_cols],  test_df [\"sepsis_label\"]\n",
    "\n",
    "print(f\"Train size: {X_train.shape[0]}   Test size: {X_test.shape[0]}\")\n",
    "print(\"Test label distribution:\\n\", y_test.value_counts(), \"\\n\")\n",
    "\n",
    "# ─── 8) Logistic Regression with scaling ────────────────────────────────────────\n",
    "log_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\",    LogisticRegression(\n",
    "                  solver=\"saga\",\n",
    "                  max_iter=2000,\n",
    "                  class_weight=\"balanced\",\n",
    "                  random_state=42\n",
    "              ))\n",
    "])\n",
    "log_pipeline.fit(X_train, y_train)\n",
    "print(\"Logistic Regression (scaled) results:\")\n",
    "print(classification_report(y_test, log_pipeline.predict(X_test)))\n",
    "\n",
    "# ─── 9) Random Forest baseline ─────────────────────────────────────────────────\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Random Forest results:\")\n",
    "print(classification_report(y_test, rf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109e1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
